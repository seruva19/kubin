general:
  device: cuda
  cache_dir: models
  model_name: kd40
  output_dir: output
  pipeline: native
  mock: false
  profiler: none
  extensions_path: extensions
  enabled_extensions: null
  disabled_extensions: null
  extensions_order: kd-upscaler;kd-animation,kd-video,kd-image-browser,kd-networks,kd-training
  skip_install: false
  safe_mode: false
  share: none
  never_unload_models: null

gradio:
  server_name: 127.0.0.1
  server_port: 7860
  concurrency_count: 2
  debug: true
  theme: default
  analytics: true

ui:
  image_width_min: 64
  image_width_max: 2048
  image_width_step: 64
  image_width_default: 1024
  image_height_min: 64
  image_height_max: 2048
  image_height_step: 64
  image_height_default: 1024
  decoder_steps_default: 50
  max_batch_count: 64
  aspect_ratio_list: 1:1;13:6;2:1;16:9;3:2;4:3;5:4;4:5;3:4;2:3;9:16;6:13;1:2
  allow_params_panel_resize: true
  enable_vertical_alignment: false
  collapse_advanced_params: false
  full_screen_panel: false
  side_tabs: true
  show_help_text: false
  progress_poll_interval: 2
  mix_image_count: 2
  restore_params_on_launch: false
  
native:
  available_text_encoders: default;google/flan-ul2;pszemraj/flan-ul2-text-encoder;JulesGo/t5-v1_1-xxl-fp8
  text_encoder: pszemraj/flan-ul2-text-encoder
  use_kandinsky31_flash: false
  available_optimization_flags: kd21_flash_attention;kd30_low_vram;kd31_low_vram;kd40_flash_attention;kd40_sage_attention;kd40_t2v_tenc_int8_ao_quantization;kd40_t2v_vae_int8_ao_quantization;kd40_t2v_dit_int8_ao_quantization;kd40_t2v_tenc_int8_oq_quantization;kd40_t2v_vae_int8_oq_quantization;kd40_t2v_dit_int8_oq_quantization;kd40_v2a_mm_int8_bnb_quantization;kd40_v2a_mm_nf4_bnb_quantization;kd40_v2a_vae_int8_bnb_quantization;kd40_v2a_vae_nf4_bnb_quantization;kd40_v2a_unet_int8_bnb_quantization;kd40_v2a_unet_nf4_bnb_quantization;kd40_vae_tiling;kd40_vae_slicing;kd40_model_offload;kd40_save_quantized_weights
  optimization_flags: kd30_low_vram;kd31_low_vram;kd40_t2v_tenc_int8_ao_quantization;kd40_t2v_vae_int8_ao_quantization;kd40_t2v_dit_int8_ao_quantization;kd40_v2a_vae_int8_bnb_quantization;kd40_v2a_unet_int8_bnb_quantization;kd40_vae_tiling;kd40_vae_slicing;kd40_v2a_mm_nf4_bnb_quantization

diffusers:
  half_precision_weights: true
  enable_xformers: false
  enable_sdp_attention: false
  enable_sliced_attention: false
  channels_last_memory: false
  sequential_cpu_offload: false
  full_model_offload: false
  torch_code_compilation: false
  use_deterministic_algorithms: false 
  use_tf32_mode: false 
  attention_slice_size: max
  run_prior_on_cpu: false 
  
