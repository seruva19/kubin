metrics:
  scheduler_scale: 5
  scale_factor:
  - 1.0
  - 2.0
  - 2.0
  resolution: 512
optimizations:
  use_torch_compile: false
model:
  checkpoint_path: ai-forever/Kandinsky-5.0-T2V-Lite-nocfg-10s
  num_steps: 50
  guidance_weight: 1.0
  duration: 10
  dit_params:
    in_visual_dim: 16
    out_visual_dim: 16
    time_dim: 512
    patch_size:
    - 1
    - 2
    - 2
    model_dim: 1792
    ff_dim: 7168
    num_text_blocks: 2
    num_visual_blocks: 32
    axes_dims:
    - 16
    - 24
    - 24
    visual_cond: true
    in_text_dim: 3584
    in_text_dim2: 768
  attention:
    type: nabla
    causal: false
    local: false
    glob: false
    window: 3
    P: 0.9
    wT: 11
    wW: 3
    wH: 3
    add_sta: true
    method: topcdf
  vae:
    checkpoint_path: hunyuanvideo-community/HunyuanVideo
    name: hunyuan
    tile_threshold: 450
  text_embedder:
    qwen:
      emb_size: 3584
      checkpoint_path: Qwen/Qwen2.5-VL-7B-Instruct
      max_length: 256
    clip:
      checkpoint_path: openai/clip-vit-large-patch14
      emb_size: 768
      max_length: 77
magcache:
  mag_ratios: [0.8736, 0, 1.12136, 0, 1.07896, 0, 1.06666, 0, 1.06235, 0, 1.03925, 0, 1.04018, 0, 1.0355, 0, 1.0327, 0, 1.02839, 0, 1.02768, 0, 1.02488, 0, 1.02143, 0, 1.02133, 0, 1.01715, 0, 1.01943, 0, 1.02177, 0, 1.01829, 0, 1.01747, 0, 1.01626, 0, 1.01559, 0, 1.01435, 0, 1.01435, 0, 1.01571, 0, 1.01312, 0, 1.01338, 0, 1.01437, 0, 1.01211, 0, 1.01237, 0, 1.01356, 0, 1.0101, 0, 1.01194, 0, 1.00898, 0, 1.0091, 0, 1.0108, 0, 1.00705, 0, 1.0018, 0, 1.01209, 0, 1.00525, 0, 1.00098, 0, 0.99914, 0, 0.99592, 0, 0.99089, 0, 0.98506, 0, 0.97495, 0, 0.9604, 0, 0.93492, 0, 0.89367, 0, 0.79353, 0]
