metrics:
  scheduler_scale: 5
  scale_factor:
  - 1.0
  - 2.0
  - 2.0
  resolution: 512
optimizations:
  use_torch_compile: true
  use_flash_attention: true
model:
  checkpoint_path: ai-forever/Kandinsky-5.0-T2V-Lite-sft-10s
  num_steps: 50
  guidance_weight: 5.0
  duration: 10
  dit_params:
    in_visual_dim: 16
    out_visual_dim: 16
    time_dim: 512
    patch_size:
    - 1
    - 2
    - 2
    model_dim: 1792
    ff_dim: 7168
    num_text_blocks: 2
    num_visual_blocks: 32
    axes_dims:
    - 16
    - 24
    - 24
    visual_cond: true
    in_text_dim: 3584
    in_text_dim2: 768
  attention:
    type: nabla
    causal: false
    local: false
    glob: false
    window: 3
    P: 0.9
    wT: 11
    wW: 3
    wH: 3
    add_sta: true
    method: topcdf
  vae:
    checkpoint_path: "hunyuanvideo-community/HunyuanVideo"
    name: "hunyuan"
    tile_threshold: 450
  text_embedder:
    qwen: 
      emb_size: 3584
      checkpoint_path: "Qwen/Qwen2.5-VL-7B-Instruct"
      max_length: 256
    clip:
      checkpoint_path: "openai/clip-vit-large-patch14"
      emb_size: 768
      max_length: 77

magcache:
  mag_ratios: [0.92261, 0.92261, 0.95898, 0.95962, 1.04862, 1.04855, 1.0806, 1.08045, 1.04405, 1.0445, 1.03587, 1.03619, 1.03789, 1.03785, 1.03485, 1.03514, 1.03724, 1.03814, 1.02484, 1.02502, 1.02525, 1.02508, 1.02473, 1.02532, 1.02625, 1.02706, 1.0197, 1.02011, 1.02326, 1.02324, 1.02081, 1.02116, 1.01993, 1.02047, 1.01979, 1.0205, 1.01823, 1.01852, 1.01785, 1.01813, 1.01563, 1.01606, 1.02057, 1.02083, 1.01132, 1.01207, 1.02053, 1.01959, 1.01718, 1.01749, 1.01546, 1.01589, 1.01516, 1.01525, 1.01578, 1.01608, 1.01616, 1.01618, 1.01443, 1.01466, 1.01554, 1.01568, 1.01494, 1.01515, 1.01567, 1.01572, 1.01418, 1.01458, 1.01601, 1.01618, 1.01491, 1.01508, 1.0162, 1.01625, 1.01412, 1.01419, 1.01431, 1.01437, 1.0106, 1.0108, 1.01428, 1.01427, 1.01222, 1.01236, 1.00812, 1.00818, 1.00759, 1.00764, 1.001, 1.00119, 0.98798, 0.98819, 0.9727, 0.97279, 0.93234, 0.93213, 0.83781, 0.83746]