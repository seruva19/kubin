metrics:
  scale_factor:
  - 1.0
  - 2.0
  - 2.0
  resolution: 512
optimizations:
  use_torch_compile: false
model:
  checkpoint_path: ai-forever/Kandinsky-5.0-T2V-Lite-nocfg-5s
  num_steps: 50
  guidance_weight: 1.0
  duration: 5
  dit_params:
    in_visual_dim: 16
    out_visual_dim: 16
    time_dim: 512
    patch_size:
    - 1
    - 2
    - 2
    model_dim: 1792
    ff_dim: 7168
    num_text_blocks: 2
    num_visual_blocks: 32
    axes_dims:
    - 16
    - 24
    - 24
    visual_cond: true
    in_text_dim: 3584
    in_text_dim2: 768
  attention:
    type: flash
    causal: false
    local: false
    glob: false
    window: 3
  vae:
    checkpoint_path: "hunyuanvideo-community/HunyuanVideo"
    name: "hunyuan"
    tile_threshold: 450
  text_embedder:
    qwen: 
      emb_size: 3584
      checkpoint_path: "Qwen/Qwen2.5-VL-7B-Instruct"
      max_length: 256
    clip:
      checkpoint_path: "openai/clip-vit-large-patch14"
      emb_size: 768
      max_length: 77
magcache:
  mag_ratios: [0.8827, 0, 1.14399, 0, 1.08362, 0, 1.06681, 0, 1.05906, 0, 1.03969, 0, 1.03835, 0, 1.03338, 0, 1.031, 0, 1.02616, 0, 1.02654, 0, 1.02322, 0, 1.02078, 0, 1.02, 0, 1.01673, 0, 1.01353, 0, 1.02175, 0, 1.0156, 0, 1.01616, 0, 1.01557, 0, 1.0131, 0, 1.01264, 0, 1.01378, 0, 1.0147, 0, 1.0109, 0, 1.01178, 0, 1.01248, 0, 1.0111, 0, 1.0099, 0, 1.01248, 0, 1.00721, 0, 1.01134, 0, 1.00752, 0, 1.00837, 0, 1.00817, 0, 1.00475, 0, 0.99937, 0, 1.01171, 0, 1.00434, 0, 0.99868, 0, 0.9969, 0, 0.995, 0, 0.98869, 0, 0.98454, 0, 0.97462, 0, 0.95885, 0, 0.93354, 0, 0.88895, 0, 0.78835, 0]
